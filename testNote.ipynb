{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模仿官方的调用测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'a')\n",
      "(2, 'b')\n",
      "(3, 'c')\n"
     ]
    }
   ],
   "source": [
    "l1 = [1,2,3]\n",
    "l2 = [\"a\", \"b\", \"c\"]\n",
    "for i in zip(l1, l2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  3 14:30:50 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.07                 Driver Version: 566.07         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P8              3W /  175W |     512MiB /  16376MiB |      6%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     42200    C+G   ...)\\AirPodsDesktop\\AirPodsDesktop.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\repos\\YOLOv8Core\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103  Python-3.12.4 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 16376MiB)\n",
      "Setup complete  (32 CPUs, 31.6 GB RAM, 53.4/512.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO;\n",
    "from IPython.display import display, Image;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=yolov8x.pt conf=0.25 source='./dog.jpeg' save=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\repos\\YOLOv8Core\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 1 backpack, 36.1ms\n",
      "Speed: 3.2ms preprocess, 36.1ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(f\"{HOME}/weights/yolov8m.pt\")\n",
    "results = model.predict(source='./dog.jpeg', conf=0.25, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查模型结构+输出结果结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['orig_img', 'orig_shape', 'boxes', 'masks', 'probs', 'keypoints', 'obb', 'speed', 'names', 'path', 'save_dir', '_keys'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].__dict__.keys()\n",
    "# dir(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     68.527,      249.58,      644.23,      929.14],\n",
       "       [          0,      354.16,      637.18,      1275.4],\n",
       "       [     627.43,      733.73,      695.97,      787.49],\n",
       "       [          0,      675.53,      439.95,      1279.5]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].orig_shape,results[0].boxes\\\n",
    "# results[0].names\n",
    "results[0].boxes.xyxy.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'person', 'car', 'backpack']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[results[0].names[cls] for cls in results[0].boxes.cls.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DetectionModel(\n",
       "   (model): Sequential(\n",
       "     (0): Conv(\n",
       "       (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (1): Conv(\n",
       "       (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (2): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): Conv(\n",
       "       (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (4): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-3): 4 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (5): Conv(\n",
       "       (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (6): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-3): 4 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (7): Conv(\n",
       "       (conv): Conv2d(384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (8): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (9): SPPF(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (11): Concat()\n",
       "     (12): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(960, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (14): Concat()\n",
       "     (15): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (16): Conv(\n",
       "       (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (17): Concat()\n",
       "     (18): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (19): Conv(\n",
       "       (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (20): Concat()\n",
       "     (21): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(960, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (22): Detect(\n",
       "       (cv2): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (cv3): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (dfl): DFL(\n",
       "         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " dict_keys(['date', 'version', 'license', 'docs', 'epoch', 'best_fitness', 'model', 'ema', 'updates', 'optimizer', 'train_args']))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import ultralytics;\n",
    "import torchvision;\n",
    "import torch;\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu';\n",
    "model = torch.load('./weights/yolov8m.pt', map_location=device);\n",
    "model['model'],model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8m summary: 295 layers, 25,902,640 parameters, 0 gradients\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(295, 25902640, 0, 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['model'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试构建基于ultralytics的视频检测框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103  Python-3.12.4 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 16376MiB)\n",
      "Setup complete  (32 CPUs, 31.6 GB RAM, 53.3/512.0 GB disk)\n",
      "\n",
      "image 1/1 e:\\repos\\YOLOv8Core\\crossing.jpg: 384x640 5 persons, 3 cars, 2 motorcycles, 1 truck, 11.7ms\n",
      "Speed: 1.7ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import ultralytics;\n",
    "\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('./weights/yolov8m.pt');\n",
    "results = model.predict(source='crossing.jpg', show=True, save=False);\n",
    "\n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 1 person, 2 sheeps, 1 cow, 1 backpack, 1 handbag, 77.7ms\n",
      "Speed: 4.2ms preprocess, 77.7ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread('deer&dear.jpg');\n",
    "results = model.predict(im,conf=0.25, show=True);\n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows();\n",
    "cv2.imwrite('./outputs/deer&dear.jpg',results[0].orig_img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103  Python-3.12.4 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 16376MiB)\n",
      "Setup complete  (32 CPUs, 31.6 GB RAM, 53.3/512.0 GB disk)\n",
      "\n",
      "0: 384x640 19 persons, 4 bicycles, 2 benchs, 1 handbag, 1 potted plant, 497.2ms\n",
      "Speed: 20.3ms preprocess, 497.2ms inference, 271.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 handbag, 1 potted plant, 59.2ms\n",
      "Speed: 12.9ms preprocess, 59.2ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 handbag, 1 potted plant, 28.8ms\n",
      "Speed: 16.7ms preprocess, 28.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 handbag, 1 potted plant, 67.0ms\n",
      "Speed: 11.6ms preprocess, 67.0ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 handbag, 1 potted plant, 32.5ms\n",
      "Speed: 6.6ms preprocess, 32.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 2 handbags, 1 potted plant, 58.5ms\n",
      "Speed: 17.3ms preprocess, 58.5ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 bicycles, 1 bench, 2 handbags, 1 potted plant, 93.1ms\n",
      "Speed: 3.3ms preprocess, 93.1ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 handbag, 1 potted plant, 48.8ms\n",
      "Speed: 15.8ms preprocess, 48.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 bicycles, 1 bench, 1 handbag, 1 potted plant, 48.1ms\n",
      "Speed: 11.9ms preprocess, 48.1ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 bicycles, 1 bench, 1 handbag, 1 potted plant, 36.4ms\n",
      "Speed: 7.1ms preprocess, 36.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 1 bench, 2 handbags, 1 potted plant, 36.5ms\n",
      "Speed: 8.9ms preprocess, 36.5ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 2 handbags, 1 potted plant, 37.4ms\n",
      "Speed: 5.8ms preprocess, 37.4ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 2 handbags, 1 potted plant, 51.9ms\n",
      "Speed: 12.2ms preprocess, 51.9ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 2 handbags, 1 potted plant, 50.4ms\n",
      "Speed: 11.8ms preprocess, 50.4ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 2 benchs, 1 backpack, 1 handbag, 1 potted plant, 65.0ms\n",
      "Speed: 7.1ms preprocess, 65.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 2 benchs, 1 backpack, 1 handbag, 1 potted plant, 17.2ms\n",
      "Speed: 3.5ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 49.4ms\n",
      "Speed: 12.9ms preprocess, 49.4ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 62.3ms\n",
      "Speed: 5.0ms preprocess, 62.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 3 bicycles, 1 bench, 2 backpacks, 1 handbag, 1 potted plant, 60.9ms\n",
      "Speed: 9.0ms preprocess, 60.9ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 51.4ms\n",
      "Speed: 6.9ms preprocess, 51.4ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 50.3ms\n",
      "Speed: 11.6ms preprocess, 50.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 184.5ms\n",
      "Speed: 8.2ms preprocess, 184.5ms inference, 64.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 47.1ms\n",
      "Speed: 10.2ms preprocess, 47.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 46.6ms\n",
      "Speed: 7.7ms preprocess, 46.6ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 41.9ms\n",
      "Speed: 6.6ms preprocess, 41.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 33.1ms\n",
      "Speed: 6.3ms preprocess, 33.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 25.2ms\n",
      "Speed: 4.7ms preprocess, 25.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 43.0ms\n",
      "Speed: 7.1ms preprocess, 43.0ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 41.3ms\n",
      "Speed: 9.3ms preprocess, 41.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 28.5ms\n",
      "Speed: 4.5ms preprocess, 28.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 50.2ms\n",
      "Speed: 17.8ms preprocess, 50.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 21.7ms\n",
      "Speed: 6.0ms preprocess, 21.7ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 60.5ms\n",
      "Speed: 27.9ms preprocess, 60.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 44.6ms\n",
      "Speed: 7.1ms preprocess, 44.6ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 188.4ms\n",
      "Speed: 27.4ms preprocess, 188.4ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 bicycles, 2 benchs, 1 potted plant, 29.5ms\n",
      "Speed: 6.6ms preprocess, 29.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 bicycles, 2 benchs, 1 potted plant, 62.4ms\n",
      "Speed: 6.5ms preprocess, 62.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 6 bicycles, 1 bench, 1 potted plant, 48.2ms\n",
      "Speed: 6.3ms preprocess, 48.2ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 1 bench, 1 potted plant, 39.8ms\n",
      "Speed: 7.0ms preprocess, 39.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 bench, 1 potted plant, 39.5ms\n",
      "Speed: 9.7ms preprocess, 39.5ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 bench, 1 potted plant, 48.1ms\n",
      "Speed: 9.3ms preprocess, 48.1ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 motorcycle, 3 benchs, 1 potted plant, 50.5ms\n",
      "Speed: 12.8ms preprocess, 50.5ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 motorcycle, 3 benchs, 1 potted plant, 40.7ms\n",
      "Speed: 18.6ms preprocess, 40.7ms inference, 23.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 potted plant, 63.5ms\n",
      "Speed: 4.0ms preprocess, 63.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 bicycles, 3 benchs, 1 potted plant, 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 bicycles, 3 benchs, 1 potted plant, 162.1ms\n",
      "Speed: 6.6ms preprocess, 162.1ms inference, 28.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 15.1ms\n",
      "Speed: 4.1ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 186.9ms\n",
      "Speed: 65.1ms preprocess, 186.9ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 bicycles, 2 benchs, 1 backpack, 1 handbag, 1 potted plant, 50.3ms\n",
      "Speed: 13.1ms preprocess, 50.3ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 6 bicycles, 2 benchs, 1 backpack, 1 potted plant, 48.6ms\n",
      "Speed: 9.9ms preprocess, 48.6ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import ultralytics;\n",
    "\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "vdo = cv2.VideoCapture(\"./videos/test.mp4\");\n",
    "model = YOLO(\"./weights/yolov8m.pt\");\n",
    "count = 0;\n",
    "fps = 60\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, ori_img = vdo.read();\n",
    "    \n",
    "    if not ret:\n",
    "        break;\n",
    "    \n",
    "    result = model.predict(ori_img,conf=0.25, show=True);\n",
    "    boxes = result[0].boxes\n",
    "    \n",
    "    \n",
    "    key = cv2.waitKey(int(1000/fps));\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break;\n",
    "cv2.destroyAllWindows();\n",
    "    \n",
    "    # 获取图片\n",
    "    # img = result.imgs\n",
    "    # plt.imshow(img);\n",
    "    # plt.axis(\"off\");\n",
    "    # plt.show();\n",
    "    \n",
    "    # 获取不同的类型与方框位置\n",
    "    # boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., 26.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1., 58.,  0.,  0.,  0., 13., 24.,  0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(boxes.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model['model']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
