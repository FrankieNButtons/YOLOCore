{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模仿官方的调用测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'a')\n",
      "(2, 'b')\n",
      "(3, 'c')\n"
     ]
    }
   ],
   "source": [
    "l1 = [1,2,3]\n",
    "l2 = [\"a\", \"b\", \"c\"]\n",
    "for i in zip(l1, l2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  9 14:11:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.07                 Driver Version: 566.07         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   40C    P8              6W /  160W |     660MiB /  16376MiB |     28%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3012    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A      3812    C+G   ...ogram Files (x86)\\ToDesk\\ToDesk.exe      N/A      |\n",
      "|    0   N/A  N/A     12756    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13112    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     14356    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     15028    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     16832    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16872    C+G   ...0305\\office6\\promecefpluginhost.exe      N/A      |\n",
      "|    0   N/A  N/A     16992    C+G   ...31.0_x64__8wekyb3d8bbwe\\GameBar.exe      N/A      |\n",
      "|    0   N/A  N/A     17672    C+G   ...x64__qmba6cd70vzyy\\ArmouryCrate.exe      N/A      |\n",
      "|    0   N/A  N/A     18036    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19152    C+G   E:\\Microsoft VS Code\\Code.exe               N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\repos\\YOLOv8Core\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103  Python-3.11.5 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 16376MiB)\n",
      "Setup complete  (32 CPUs, 31.6 GB RAM, 45.7/512.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO;\n",
    "from IPython.display import display, Image;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=yolov8x.pt conf=0.25 source='./dog.jpeg' save=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\repos\\YOLOv8Core\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 1 backpack, 557.1ms\n",
      "Speed: 28.0ms preprocess, 557.1ms inference, 1075.5ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(f\"{HOME}/weights/yolov8m.pt\")\n",
    "results = model.predict(source='./dog.jpeg', conf=0.25, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查模型结构+输出结果结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['orig_img', 'orig_shape', 'boxes', 'masks', 'probs', 'keypoints', 'obb', 'speed', 'names', 'path', 'save_dir', '_keys'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].__dict__.keys()\n",
    "# dir(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     68.527,      249.58,      644.23,      929.14],\n",
       "       [          0,      354.16,      637.18,      1275.4],\n",
       "       [     627.43,      733.73,      695.97,      787.49],\n",
       "       [          0,      675.53,      439.95,      1279.5]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].orig_shape,results[0].boxes\\\n",
    "# results[0].names\n",
    "results[0].boxes.xyxy.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'person', 'car', 'backpack']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[results[0].names[cls] for cls in results[0].boxes.cls.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lapx>=0.5.2'] not found, attempting AutoUpdate...\n",
      "Retry 1/2 failed: Command 'pip install --no-cache-dir \"lapx>=0.5.2\" ' returned non-zero exit status 1.\n",
      "Retry 2/2 failed: Command 'pip install --no-cache-dir \"lapx>=0.5.2\" ' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install --no-cache-dir \"lapx>=0.5.2\" ' returned non-zero exit status 1.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32me:\\repos\\YOLOv8Core\\.venv\\Lib\\site-packages\\ultralytics\\trackers\\utils\\matching.py:10\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlap\u001b[39;00m  \u001b[38;5;66;03m# for linear_assignment\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m lap\u001b[38;5;241m.\u001b[39m__version__  \u001b[38;5;66;03m# verify package is not directory\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lap'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./dog.jpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\repos\\YOLOv8Core\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:596\u001b[0m, in \u001b[0;36mModel.track\u001b[1;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mConducts object tracking on the specified input source using the registered trackers.\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;124;03m    - Batch size is set to 1 for tracking in videos.\u001b[39;00m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrackers\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 596\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrackers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_tracker\n\u001b[0;32m    598\u001b[0m     register_tracker(\u001b[38;5;28mself\u001b[39m, persist)\n\u001b[0;32m    599\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconf\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconf\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# ByteTrack-based method needs low confidence predictions as input\u001b[39;00m\n",
      "File \u001b[1;32me:\\repos\\YOLOv8Core\\.venv\\Lib\\site-packages\\ultralytics\\trackers\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbot_sort\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BOTSORT\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbyte_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BYTETracker\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_tracker\n",
      "File \u001b[1;32me:\\repos\\YOLOv8Core\\.venv\\Lib\\site-packages\\ultralytics\\trackers\\bot_sort.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasetrack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrackState\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbyte_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BYTETracker, STrack\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m matching\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgmc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GMC\n",
      "File \u001b[1;32me:\\repos\\YOLOv8Core\\.venv\\Lib\\site-packages\\ultralytics\\trackers\\byte_tracker.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m xywh2ltwh\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasetrack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTrack, TrackState\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m matching\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkalman_filter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KalmanFilterXYAH\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSTrack\u001b[39;00m(BaseTrack):\n",
      "File \u001b[1;32me:\\repos\\YOLOv8Core\\.venv\\Lib\\site-packages\\ultralytics\\trackers\\utils\\matching.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_requirements\n\u001b[0;32m     16\u001b[0m     check_requirements(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlapx>=0.5.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# update to lap package from https://github.com/rathaROG/lapx\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlap\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlinear_assignment\u001b[39m(cost_matrix: np\u001b[38;5;241m.\u001b[39mndarray, thresh: \u001b[38;5;28mfloat\u001b[39m, use_lap: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    Perform linear assignment using either the scipy or lap.lapjv method.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m        >>> matched_indices, unmatched_a, unmatched_b = linear_assignment(cost_matrix, thresh, use_lap=True)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lap'"
     ]
    }
   ],
   "source": [
    "model.track(source='./dog.jpeg', persist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DetectionModel(\n",
       "   (model): Sequential(\n",
       "     (0): Conv(\n",
       "       (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (1): Conv(\n",
       "       (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (2): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): Conv(\n",
       "       (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (4): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-3): 4 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (5): Conv(\n",
       "       (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (6): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-3): 4 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (7): Conv(\n",
       "       (conv): Conv2d(384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (8): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (9): SPPF(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (11): Concat()\n",
       "     (12): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(960, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (14): Concat()\n",
       "     (15): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (16): Conv(\n",
       "       (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (17): Concat()\n",
       "     (18): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (19): Conv(\n",
       "       (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (20): Concat()\n",
       "     (21): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(960, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (22): Detect(\n",
       "       (cv2): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (cv3): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(192, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (dfl): DFL(\n",
       "         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " dict_keys(['date', 'version', 'license', 'docs', 'epoch', 'best_fitness', 'model', 'ema', 'updates', 'optimizer', 'train_args']))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import ultralytics;\n",
    "import torchvision;\n",
    "import torch;\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu';\n",
    "model = torch.load('./weights/yolov8m.pt', map_location=device);\n",
    "model['model'],model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8m summary: 295 layers, 25,902,640 parameters, 0 gradients\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(295, 25902640, 0, 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['model'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试构建基于ultralytics的视频检测框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103  Python-3.12.4 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 16376MiB)\n",
      "Setup complete  (32 CPUs, 31.6 GB RAM, 53.3/512.0 GB disk)\n",
      "\n",
      "image 1/1 e:\\repos\\YOLOv8Core\\crossing.jpg: 384x640 5 persons, 3 cars, 2 motorcycles, 1 truck, 11.7ms\n",
      "Speed: 1.7ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import ultralytics;\n",
    "\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('./weights/yolov8m.pt');\n",
    "results = model.predict(source='crossing.jpg', show=True, save=False);\n",
    "\n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 1 person, 2 sheeps, 1 cow, 1 backpack, 1 handbag, 77.7ms\n",
      "Speed: 4.2ms preprocess, 77.7ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread('deer&dear.jpg');\n",
    "results = model.predict(im,conf=0.25, show=True);\n",
    "cv2.waitKey(0);\n",
    "cv2.destroyAllWindows();\n",
    "cv2.imwrite('./outputs/deer&dear.jpg',results[0].orig_img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103  Python-3.12.4 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 16376MiB)\n",
      "Setup complete  (32 CPUs, 31.6 GB RAM, 53.3/512.0 GB disk)\n",
      "\n",
      "0: 384x640 19 persons, 4 bicycles, 2 benchs, 1 handbag, 1 potted plant, 497.2ms\n",
      "Speed: 20.3ms preprocess, 497.2ms inference, 271.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 handbag, 1 potted plant, 59.2ms\n",
      "Speed: 12.9ms preprocess, 59.2ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 handbag, 1 potted plant, 28.8ms\n",
      "Speed: 16.7ms preprocess, 28.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 handbag, 1 potted plant, 67.0ms\n",
      "Speed: 11.6ms preprocess, 67.0ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 handbag, 1 potted plant, 32.5ms\n",
      "Speed: 6.6ms preprocess, 32.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 2 handbags, 1 potted plant, 58.5ms\n",
      "Speed: 17.3ms preprocess, 58.5ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 bicycles, 1 bench, 2 handbags, 1 potted plant, 93.1ms\n",
      "Speed: 3.3ms preprocess, 93.1ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 handbag, 1 potted plant, 48.8ms\n",
      "Speed: 15.8ms preprocess, 48.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 bicycles, 1 bench, 1 handbag, 1 potted plant, 48.1ms\n",
      "Speed: 11.9ms preprocess, 48.1ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 bicycles, 1 bench, 1 handbag, 1 potted plant, 36.4ms\n",
      "Speed: 7.1ms preprocess, 36.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 1 bench, 2 handbags, 1 potted plant, 36.5ms\n",
      "Speed: 8.9ms preprocess, 36.5ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 2 handbags, 1 potted plant, 37.4ms\n",
      "Speed: 5.8ms preprocess, 37.4ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 2 handbags, 1 potted plant, 51.9ms\n",
      "Speed: 12.2ms preprocess, 51.9ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 2 handbags, 1 potted plant, 50.4ms\n",
      "Speed: 11.8ms preprocess, 50.4ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 2 benchs, 1 backpack, 1 handbag, 1 potted plant, 65.0ms\n",
      "Speed: 7.1ms preprocess, 65.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 2 benchs, 1 backpack, 1 handbag, 1 potted plant, 17.2ms\n",
      "Speed: 3.5ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 49.4ms\n",
      "Speed: 12.9ms preprocess, 49.4ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 62.3ms\n",
      "Speed: 5.0ms preprocess, 62.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 3 bicycles, 1 bench, 2 backpacks, 1 handbag, 1 potted plant, 60.9ms\n",
      "Speed: 9.0ms preprocess, 60.9ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 51.4ms\n",
      "Speed: 6.9ms preprocess, 51.4ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 50.3ms\n",
      "Speed: 11.6ms preprocess, 50.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 184.5ms\n",
      "Speed: 8.2ms preprocess, 184.5ms inference, 64.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 3 bicycles, 1 bench, 1 backpack, 1 handbag, 1 potted plant, 47.1ms\n",
      "Speed: 10.2ms preprocess, 47.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 46.6ms\n",
      "Speed: 7.7ms preprocess, 46.6ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 41.9ms\n",
      "Speed: 6.6ms preprocess, 41.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 33.1ms\n",
      "Speed: 6.3ms preprocess, 33.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 25.2ms\n",
      "Speed: 4.7ms preprocess, 25.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 43.0ms\n",
      "Speed: 7.1ms preprocess, 43.0ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 41.3ms\n",
      "Speed: 9.3ms preprocess, 41.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 28.5ms\n",
      "Speed: 4.5ms preprocess, 28.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 2 benchs, 1 handbag, 1 potted plant, 50.2ms\n",
      "Speed: 17.8ms preprocess, 50.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 21.7ms\n",
      "Speed: 6.0ms preprocess, 21.7ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 60.5ms\n",
      "Speed: 27.9ms preprocess, 60.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 44.6ms\n",
      "Speed: 7.1ms preprocess, 44.6ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 188.4ms\n",
      "Speed: 27.4ms preprocess, 188.4ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 bicycles, 2 benchs, 1 potted plant, 29.5ms\n",
      "Speed: 6.6ms preprocess, 29.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 bicycles, 2 benchs, 1 potted plant, 62.4ms\n",
      "Speed: 6.5ms preprocess, 62.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 6 bicycles, 1 bench, 1 potted plant, 48.2ms\n",
      "Speed: 6.3ms preprocess, 48.2ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 1 bench, 1 potted plant, 39.8ms\n",
      "Speed: 7.0ms preprocess, 39.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 bench, 1 potted plant, 39.5ms\n",
      "Speed: 9.7ms preprocess, 39.5ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 bench, 1 potted plant, 48.1ms\n",
      "Speed: 9.3ms preprocess, 48.1ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 motorcycle, 3 benchs, 1 potted plant, 50.5ms\n",
      "Speed: 12.8ms preprocess, 50.5ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 bicycles, 1 motorcycle, 3 benchs, 1 potted plant, 40.7ms\n",
      "Speed: 18.6ms preprocess, 40.7ms inference, 23.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 potted plant, 63.5ms\n",
      "Speed: 4.0ms preprocess, 63.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 bicycles, 3 benchs, 1 potted plant, 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 bicycles, 3 benchs, 1 potted plant, 162.1ms\n",
      "Speed: 6.6ms preprocess, 162.1ms inference, 28.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 15.1ms\n",
      "Speed: 4.1ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 bicycles, 3 benchs, 1 handbag, 1 potted plant, 186.9ms\n",
      "Speed: 65.1ms preprocess, 186.9ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 bicycles, 2 benchs, 1 backpack, 1 handbag, 1 potted plant, 50.3ms\n",
      "Speed: 13.1ms preprocess, 50.3ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 6 bicycles, 2 benchs, 1 backpack, 1 potted plant, 48.6ms\n",
      "Speed: 9.9ms preprocess, 48.6ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import ultralytics;\n",
    "\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "vdo = cv2.VideoCapture(\"./videos/test.mp4\");\n",
    "model = YOLO(\"./weights/yolov8m.pt\");\n",
    "count = 0;\n",
    "fps = 60\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, ori_img = vdo.read();\n",
    "    \n",
    "    if not ret:\n",
    "        break;\n",
    "    \n",
    "    result = model.predict(ori_img,conf=0.25, show=True);\n",
    "    boxes = result[0].boxes\n",
    "    \n",
    "    \n",
    "    key = cv2.waitKey(int(1000/fps));\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break;\n",
    "cv2.destroyAllWindows();\n",
    "    \n",
    "    # 获取图片\n",
    "    # img = result.imgs\n",
    "    # plt.imshow(img);\n",
    "    # plt.axis(\"off\");\n",
    "    # plt.show();\n",
    "    \n",
    "    # 获取不同的类型与方框位置\n",
    "    # boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., 26.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1., 58.,  0.,  0.,  0., 13., 24.,  0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(boxes.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model['model']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
